{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9890909090909092,
  "eval_steps": 500,
  "global_step": 720,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08311688311688312,
      "grad_norm": 0.9601795077323914,
      "learning_rate": 0.00019472222222222221,
      "loss": 2.7975,
      "step": 20
    },
    {
      "epoch": 0.16623376623376623,
      "grad_norm": 0.5932925343513489,
      "learning_rate": 0.00018916666666666667,
      "loss": 2.5809,
      "step": 40
    },
    {
      "epoch": 0.24935064935064935,
      "grad_norm": 0.5854752659797668,
      "learning_rate": 0.00018361111111111112,
      "loss": 2.5986,
      "step": 60
    },
    {
      "epoch": 0.33246753246753247,
      "grad_norm": 0.5486156344413757,
      "learning_rate": 0.00017805555555555554,
      "loss": 2.5972,
      "step": 80
    },
    {
      "epoch": 0.4155844155844156,
      "grad_norm": 0.6695467829704285,
      "learning_rate": 0.00017250000000000002,
      "loss": 2.5642,
      "step": 100
    },
    {
      "epoch": 0.4987012987012987,
      "grad_norm": 0.6725851893424988,
      "learning_rate": 0.00016694444444444447,
      "loss": 2.5224,
      "step": 120
    },
    {
      "epoch": 0.5818181818181818,
      "grad_norm": 0.6869274973869324,
      "learning_rate": 0.0001613888888888889,
      "loss": 2.4867,
      "step": 140
    },
    {
      "epoch": 0.6649350649350649,
      "grad_norm": 0.6574729084968567,
      "learning_rate": 0.00015583333333333334,
      "loss": 2.5092,
      "step": 160
    },
    {
      "epoch": 0.7480519480519481,
      "grad_norm": 0.7232973575592041,
      "learning_rate": 0.0001502777777777778,
      "loss": 2.5355,
      "step": 180
    },
    {
      "epoch": 0.8311688311688312,
      "grad_norm": 0.6665294766426086,
      "learning_rate": 0.00014472222222222222,
      "loss": 2.5087,
      "step": 200
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.585642397403717,
      "learning_rate": 0.00013916666666666667,
      "loss": 2.5036,
      "step": 220
    },
    {
      "epoch": 0.9974025974025974,
      "grad_norm": 0.666831910610199,
      "learning_rate": 0.00013361111111111112,
      "loss": 2.5112,
      "step": 240
    },
    {
      "epoch": 1.078961038961039,
      "grad_norm": 0.6234948039054871,
      "learning_rate": 0.00012805555555555555,
      "loss": 2.4729,
      "step": 260
    },
    {
      "epoch": 1.162077922077922,
      "grad_norm": 0.6819286346435547,
      "learning_rate": 0.00012250000000000002,
      "loss": 2.462,
      "step": 280
    },
    {
      "epoch": 1.2451948051948052,
      "grad_norm": 0.7062719464302063,
      "learning_rate": 0.00011694444444444446,
      "loss": 2.4676,
      "step": 300
    },
    {
      "epoch": 1.3283116883116883,
      "grad_norm": 0.6761966943740845,
      "learning_rate": 0.0001113888888888889,
      "loss": 2.4833,
      "step": 320
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 0.7953001856803894,
      "learning_rate": 0.00010583333333333334,
      "loss": 2.4632,
      "step": 340
    },
    {
      "epoch": 1.4945454545454546,
      "grad_norm": 0.8372156023979187,
      "learning_rate": 0.00010027777777777779,
      "loss": 2.4276,
      "step": 360
    },
    {
      "epoch": 1.5776623376623378,
      "grad_norm": 0.7748637199401855,
      "learning_rate": 9.472222222222222e-05,
      "loss": 2.4266,
      "step": 380
    },
    {
      "epoch": 1.660779220779221,
      "grad_norm": 0.791736364364624,
      "learning_rate": 8.916666666666667e-05,
      "loss": 2.4462,
      "step": 400
    },
    {
      "epoch": 1.743896103896104,
      "grad_norm": 0.6960370540618896,
      "learning_rate": 8.361111111111111e-05,
      "loss": 2.4127,
      "step": 420
    },
    {
      "epoch": 1.827012987012987,
      "grad_norm": 0.7189653515815735,
      "learning_rate": 7.805555555555556e-05,
      "loss": 2.4439,
      "step": 440
    },
    {
      "epoch": 1.9101298701298701,
      "grad_norm": 0.8001246452331543,
      "learning_rate": 7.25e-05,
      "loss": 2.4123,
      "step": 460
    },
    {
      "epoch": 1.9932467532467533,
      "grad_norm": 0.7938411831855774,
      "learning_rate": 6.694444444444444e-05,
      "loss": 2.4427,
      "step": 480
    },
    {
      "epoch": 2.0748051948051947,
      "grad_norm": 0.7134169340133667,
      "learning_rate": 6.13888888888889e-05,
      "loss": 2.4141,
      "step": 500
    },
    {
      "epoch": 2.157922077922078,
      "grad_norm": 0.8018350601196289,
      "learning_rate": 5.583333333333334e-05,
      "loss": 2.4139,
      "step": 520
    },
    {
      "epoch": 2.241038961038961,
      "grad_norm": 0.824090838432312,
      "learning_rate": 5.027777777777778e-05,
      "loss": 2.4342,
      "step": 540
    },
    {
      "epoch": 2.324155844155844,
      "grad_norm": 0.8000701069831848,
      "learning_rate": 4.472222222222223e-05,
      "loss": 2.3852,
      "step": 560
    },
    {
      "epoch": 2.4072727272727272,
      "grad_norm": 0.8207470774650574,
      "learning_rate": 3.9166666666666665e-05,
      "loss": 2.3871,
      "step": 580
    },
    {
      "epoch": 2.4903896103896104,
      "grad_norm": 0.906556248664856,
      "learning_rate": 3.3611111111111116e-05,
      "loss": 2.4248,
      "step": 600
    },
    {
      "epoch": 2.5735064935064935,
      "grad_norm": 0.883638322353363,
      "learning_rate": 2.8055555555555557e-05,
      "loss": 2.3632,
      "step": 620
    },
    {
      "epoch": 2.6566233766233767,
      "grad_norm": 0.9035760164260864,
      "learning_rate": 2.25e-05,
      "loss": 2.3592,
      "step": 640
    },
    {
      "epoch": 2.73974025974026,
      "grad_norm": 0.9267725944519043,
      "learning_rate": 1.6944444444444446e-05,
      "loss": 2.3775,
      "step": 660
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 0.9202423095703125,
      "learning_rate": 1.138888888888889e-05,
      "loss": 2.3938,
      "step": 680
    },
    {
      "epoch": 2.905974025974026,
      "grad_norm": 0.8234609365463257,
      "learning_rate": 5.833333333333334e-06,
      "loss": 2.398,
      "step": 700
    },
    {
      "epoch": 2.9890909090909092,
      "grad_norm": 0.8328408598899841,
      "learning_rate": 2.777777777777778e-07,
      "loss": 2.3649,
      "step": 720
    }
  ],
  "logging_steps": 20,
  "max_steps": 720,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2690848500678656e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
