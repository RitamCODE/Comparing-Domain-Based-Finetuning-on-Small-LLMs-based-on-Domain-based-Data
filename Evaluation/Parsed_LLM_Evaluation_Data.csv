paper_id,question,better_answer,relevance_a,correctness_a,completeness_a,relevance_b,correctness_b,completeness_b
1911.10742,How big is the ANTISCAM dataset? ,A,,,,,,
1911.10742,How is intent annotated?,,2.0,2.0,2.0,1.0,1.0,1.0
1911.10742,What are the baselines outperformed by this work?,B,,,,,,
1911.10742,What are the evaluation metrics and criteria used to evaluate the model performance?,,,,,,,
1904.09131,What is the accuracy of this model compared to sota?,,,,,,,
1611.06322,What previous methods do they compare against?,B,,,,,,
1611.06322,What is their evaluation metric?,A,,,,,,
1611.06322,Are their methods fully supervised?,A,,,,,,
1611.06322,What languages do they evaluate their methods on?,,,,,,,
1611.06322,How do they define rumors?,Tie,,,,,,
1604.02038,What baselines did they compare with?,A,,,,,,
1604.02038,Which tasks are explored in this paper?,A,,,,,,
1911.04474,Which NER dataset do they use?,Tie,,,,,,
1911.04474,How do they incorporate direction and relative distance in attention?,B,,,,,,
1905.00840,What was their accuracy score?,B,,,,,,
1905.00840,What are the state-of-the-art systems?,B,,,,,,
1905.00840,What dataset did they evaluate on?,B,,,,,,
1810.02229,What are the contributions of this paper?,,,,,,,
1810.02229,What are the baselines this paper uses?,A,,,,,,
1909.00091,How do they decide what is the semantic concept label of particular cluster?,A,,,,,,
1909.00091,How do they discover coherent word clusters?,A,,,,,,
1909.00091,How big are two introduced datasets?,A,,,,,,
1909.00091,What are strong baselines authors used?,B,,,,,,
1909.04387,How do data-driven models usually respond to abuse?,B,,,,,,
1909.04387,How much data did they gather from crowdsourcing?,A,,,,,,
1909.04387,How many different strategies were evaluated?,A,,,,,,
1805.11937,What morphological typologies are considered?,,,,,,,
1805.11937,What type of morphological features are used?,B,,,,,,
1909.09070,What datasets are used in this paper?,A,,,,,,
1909.09070,What language are the captions in?,A,,,,,,
1909.09070,What ad-hoc approaches are explored?,B,,,,,,
1909.09070,What ad-hoc approaches are explored?,,,,,,,
1909.09070,What supervised baselines did they compare with?,Tie,,,,,,
1909.09070,Where do their figure and captions come from?,B,,,,,,
1708.05521,what was the baseline?,A,,,,,,
1708.05521,what was their result?,B,,,,,,
1708.05521,what dataset was used?,B,,,,,,
1908.11049,What is their definition of hate speech?,B,,,,,,
1908.11049,What languages does the new dataset contain?,A,,,,,,
1908.11049,What aspects are considered?,,,,,,,
1908.11049,How big is their dataset?,Tie,,,,,,
1907.10676,What are the opportunities presented by the use of Semantic Web technologies in Machine Translation?,B,,,,,,
1907.10676,What are the challenges associated with the use of Semantic Web technologies in Machine Translation?,A,,,,,,
1907.10676,What are the other obstacles to automatic translations which are not mentioned in the abstract?,A,,,,,,
1906.08871,what eeg features were used?,B,,,,,,
1906.08871,what dataset was used?,B,,,,,,
2004.04124,On which datasets does LadaBERT achieve state-of-the-art?,Tie,,,,,,
1603.07252,What domain of text are they working with?,B,,,,,,
1603.07252,What dataset do they use?,Tie,,,,,,
1708.00549,What types of commonsense knowledge are they talking about?,B,1.0,1.0,1.0,2.0,1.0,1.0
1708.00549,What do they mean by intrinsic geometry of spaces of learned representations?,A,,,,,,
1905.00472,What were the most salient features extracted by the models?,A,,,,,,
1905.00472,How many languages are in the dataset?,B,,,,,,
1912.02866,"What are the parts of the ""multimodal"" resources?",A,,,,,,
1912.02866,Are annotators familiar with the science topics annotated?,A,,,,,,
1912.02866,How are the expert and crowd-sourced annotations compared to one another?,Tie,,,,,,
1912.02866,What platform do the crowd-sourced workers come from?,B,,,,,,
1912.02866,Who are considered trained experts?,A,,,,,,
1812.00382,Which model architecture do they opt for?,Tie,,,,,,
1812.00382,Which dataset do they use?,A,,,,,,
1812.00382,Which weak signal data do they use?,B,,,,,,
1903.02930,what dataset was used for training?,A,,,,,,
1903.02930,what is the size of the training data?,B,,,,,,
1903.02930,what features were derived from the videos?,A,,,,,,
1911.04873,What translation models are explored?,B,,,,,,
1911.04873,What is symbolic rewriting?,A,,,,,,
1606.07043,How do they incorporate expert knowledge into their topic model?,B,,,,,,
1606.07043,On which corpora do they evaluate on?,A,,,,,,
1611.04234,What is F-score obtained?,,,,,,,
1611.04234,What is the state-of-the-art?,B,,,,,,
1611.04234,Which Chinese social media platform does the data come from?,A,,,,,,
1611.04234,What dataset did they use?,A,,,,,,
1909.00437,What are the five downstream tasks?,A,,,,,,
1909.00437,How did they select the 50 languages they test?,Tie,,,,,,
2003.07568,What kind of evaluations do use to evaluate dialogue?,A,,,,,,
2003.07568,By how much do their cross-lingual models lag behind other models?,A,,,,,,
2003.07568,Which translation pipelines do they use to compare against?,Tie,,,,,,
2003.07568,Which languages does their newly created dataset contain?,B,,,,,,
1810.02268,what are the baselines?,B,1.0,1.0,1.0,5.0,5.0,4.0
1810.02268,what context aware models were experimented?,Tie,,,,,,
1810.02268,what languages did they experiment on?,B,,,,,,
1909.12079,How do they obtain the entity linking results in their model?,B,,,,,,
1909.12079,Which model architecture do they use?,Tie,,,,,,
1909.12079,Which datasets do they evaluate on?,B,,,,,,
2003.11687,How many domain experts were involved into creation of dataset?,A,,,,,,
2003.11687,What metrics are used for evaluation?,A,,,,,,
2003.11687,What is the performance of fine tuned model on this dataset?,B,,,,,,
2003.11687,How does labeling scheme look like?,Tie,,,,,,
2003.11687,What pretrained language model is used?,B,,,,,,
2003.11687,How big is constructed dataset?,B,,,,,,
1703.10152,What metric is considered?,B,,,,,,
1703.10152,What hand-crafted features are used?,B,,,,,,
1703.10152,What word embeddings are used?,B,,,,,,
1703.10152,How are the sentence embeddings generated?,A,,,,,,
1703.10152,What is argumentative zoning?,B,,,,,,
1907.04072,How did they obtain the tweets?,A,,,,,,
1907.04072,What baseline do they compare to?,B,,,,,,
1907.04072,What language is explored in this paper?,A,,,,,,
1907.04072,What blackmarket services do they look at?,A,,,,,,
1909.10481,What languages do they use during pretraining?,A,,,,,,
1909.10481,What is the architecture of the decoder?,B,,,,,,
1909.10481,What is the architecture of the encoder?,B,,,,,,
1909.10481,What is their baseline?,A,,,,,,
1805.04833,What human evaluation metrics do they look at?,Tie,,,,,,
1805.04833,Which automated evaluation metrics are used?,A,,,,,,
1805.04833,What baselines do they compare against?,B,,,,,,
1805.04833,What model is used to generate the premise?,B,,,,,,
1805.04833,Where are the stories collected from?,Tie,,,,,,
1805.07882,which pretrained embeddings were experimented with?,A,,,,,,
1805.07882,what datasets where used?,B,,,,,,
1805.07882,what are the state of the art methods they compare with?,B,,,,,,
2004.01820,What agreement measure is used?,A,,,,,,
2004.01820,How many annotators participated?,B,,,,,,
2004.01820,What social-network features are used?,A,,,,,,
2004.01820,What are the five factors considered?,Tie,,,,,,
2004.01820,How is cyberbullying defined?,B,,,,,,
1806.04387,What evaluation was performed on the output?,A,,,,,,
1806.04387,Where did the joke data come from?,B,,,,,,
1806.04387,What type of quotes is this system trying to generate?,B,,,,,,
1808.04122,By how much do they outperform state-of-the-art models on knowledge graph completion?,,,,,,,
1907.05338,what models did they compare with?,B,,,,,,
1907.05338,what datasets were used for testing?,Tie,,,,,,
2003.08437,What inter-annotator agreement did they obtain?,,,,,,,
2003.08437,How did they annotate the corpus?,A,,,,,,
2003.08437,What is the size of the corpus?,B,,,,,,
2003.04978,Which datasets do they use?,Tie,,,,,,
2003.04978,What models are explored in this paper?,,,,,,,
1809.08935,what features of the essays are extracted?,B,,,,,,
1809.08935,what were the evaluation metrics?,B,,,,,,
1809.08935,what model is used?,B,,,,,,
1809.08935,what future work is described?,Tie,,,,,,
1910.07924,How is the sentence alignment quality evaluated?,Tie,,,,,,
1910.07924,How is the speech alignment quality evaluated?,Tie,,,,,,
1911.11899,By how much do they outperform previous state-of-the-art in terms of top-n precision?,,,,,,,
1603.09405,By how much do they outperform existing methods?,Tie,,,,,,
1603.09405,Which datasets do they evaluate on?,B,,,,,,
1912.11585,What dataset was used in this challenge?,A,,,,,,
1912.11585,Which subsystem outperformed the others?,Tie,,,,,,
1707.09816,Do they reduce language variation of text by enhancing frequencies?,A,,,,,,
1707.09816,Which domains do they explore?,Tie,,,,,,
1707.09816,Which thesauri did they use?,A,,,,,,
1703.04009,What is their definition of hate speech?,B,,,,,,
1703.04009,What type of model do they train?,A,,,,,,
1703.04009,How many users does their dataset have?,,,,,,,
1703.04009,How long is their dataset?,Tie,,,,,,
1911.03090,In what tasks does fine-tuning all layers hurt performance?,B,,,,,,
1911.03090,Do they test against the large version of RoBERTa?,A,,,,,,
